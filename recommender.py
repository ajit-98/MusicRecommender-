import numpy as np  
import cv2
import pandas as pd
import shutil
import scipy.sparse as sparse
from scipy.special import softmax
import json
from keras.utils.vis_utils import plot_model
from keras.optimizers import Adam
from sklearn.model_selection import train_test_split
from keras.preprocessing.image import img_to_array
import json
from keras.utils import to_categorical
from keras.models import load_model,model_from_json,Sequential
from keras.layers import Dropout
from keras.callbacks import ModelCheckpoint
from keras.utils import Sequence,to_categorical
from keras.models import Model
import ml_metrics
import recmetrics
from keras import optimizers
from keras.layers.convolutional import Conv2D
from keras.layers.convolutional import MaxPooling2D
from keras.layers.core import Activation
from keras.layers.core import Flatten
from keras.layers.core import Dense
from keras import backend as K
from annoy import AnnoyIndex
import matplotlib.pyplot as plt
import argparse
import random
import os

#directories containing essential files for the recommender system 
user_latent_factors_dir = 'Metadata\\user_latent_factors.npz' #matrix containing user latent factors as columns (generated by code in Latent Matrix Factorization\factorize_matrix.py)
song_latent_factors_dir = 'Metadata\\song_latent_factors.npz' #matrix containing song latent factors as columns (generated by code in Latent Matrix Factorization\factorize_matrix.py)
song_msd_id_dir = 'Metadata\\subset_songs_msd_id.npy' #npy file containing a list of all song msd ids (msd id indexes correspond to column number in song_latent_factors_dir)
user_id_dir = 'Metadata\\subset_users.npy' #npy file containing a list of all user ids (user id indexes correspond to column number in user_latent_factors_dir)
song_user_matrix_dir = 'Metadata\\song_user_matrix.npz' #matrix containing song - user playcounts (rows represent users and columns represent songs)
id_to_songname_dir = 'Metadata\\id_to_songname.txt' #text file mapping msd id to songname + artist name
spectrogram_dir = 'Mel Specs' #directory containing Mel Spectrograms of songs in msd datatset (Obtained from Get_Audio.py)
#Directories for training, validation and test dataset respectively (empty until split_data is run) 
training_dir = "Training" 
validation_dir = "Test"
test_dir = "Validation"
trained_model_dirs = ['Models\\model 4.7.json','Models\\model 4.7.h5']

def get_msd_ids_from_dataset(spectrogram_dir,subset_songs_dir,latent_factors_dict): #get a list of all the msd_ids present in the datset 
	for root,dirs,files in os.walk(spectrogram_dir):
		root = root
		filenames = files
	local_song_ids = [get_id_from_filename(x) for x in filenames] #get msd_id from each spectrogram in the dataset
	local_song_ids = [x for x in local_song_ids if x in latent_factors_dict.keys()] #check if msd_id exists in the latent factor dictionary
	local_song_ids = set(local_song_ids) #get all unique msd_ids
	subset_songs = np.load(subset_songs_dir)
	new_subset_songs = []
	for song in subset_songs:
		if song in local_song_ids:
			new_subset_songs.append(song)
	np.save('Metadata\\new_subset_songs.npy',new_subset_songs)
	return len(new_subset_songs),new_subset_songs 

def get_user_ids_list(subset_users_dir,num_users,user_latent_factors_dict): #get ids of users to recommend music for
	subset_users = np.load(subset_users_dir)
	subset_users_list = subset_users.tolist()
	new_subset_users =subset_users_list[0:num_users]
	np.save('Metadata\\new_subset_users.npy',new_subset_users)
	return len(new_subset_users),new_subset_users

#return a dictionary mapping songs to a 20,000 dimensional categorical vector representing the top 5000 listeners
def create_output_labels(subset_songs,subset_users,user_latent_factors_dict,latent_factors_dict):  
	t= AnnoyIndex(100,'dot')
	labels_dict = {}
	num_of_classes = len(subset_users)
	for i in range(len(subset_users)):
		t.add_item(i,user_latent_factors_dict[subset_users[i]])
	t.build(10)

	for i in range(len(subset_songs)):
		nearest_neighbors = t.get_nns_by_vector(latent_factors_dict[subset_songs[i]],5000)
		labels_dict[subset_songs[i]] = to_categorical(nearest_neighbors,num_of_classes).sum(axis=0).tolist()
	with open('Metadata\\user_based_labels.json','w') as f:
		json.dump(labels_dict,f) 

	return labels_dict



def get_id_from_filename(name): #get msd_id for each spectrogram in dataset
	filename = name.split('_')[0]
	filename = filename.split('.')[0] #splitting done based on the filenames produced by Download Audio\Get_Audio.py
	return filename

#creates a dictionary mapping song/user ID to the corresponding vector/latent factor
#id file should be .npy
def get_labels_dictionary(matrix_file,id_file,transpose=False,load_npz=True,num_items = -1):  #if load_npz=True matrix file should have .npz extension

	if load_npz == True:
		matrix_npz = np.load(matrix_file)
		matrix = matrix_npz['arr_0']
	else:
		matrix = matrix_file
	print("Successfully loaded matrix of dimensions {}".format(matrix.shape))
	ids = np.load(id_file)
	if transpose == True:
		matrix = matrix.transpose()
	if num_items != -1:
		labels_dict = dict(zip(ids[0:num_items],matrix[0:num_items]))
	else:
		labels_dict = dict(zip(ids,matrix))
	#print(labels_dict)
	return labels_dict

#Seperate a single directory containing all the images into training,test and validation datasets
def split_data(image_dir,train_dir,val_dir,test_dir,latent_factors_dict,test_size,val_size):
	song_id_dict = {}
	for root,dirs,files in os.walk(image_dir,topdown=False):
		for name in files:
			song_id = get_id_from_filename(name)
			if song_id in latent_factors_dict.keys():
				if song_id in song_id_dict.keys():
					song_id_dict[song_id].append(os.path.join(root,name))
				else:
					song_id_dict[song_id] = [os.path.join(root,name)]
	train_ids,test_ids = train_test_split(list(song_id_dict.keys()),test_size=test_size)
	train_ids,val_ids = train_test_split(train_ids,test_size=val_size)
	for sid in train_ids:
		for song in song_id_dict[sid]:
			shutil.move(song,train_dir)
	for sid in test_ids:
		for song in song_id_dict[sid]:
			shutil.move(song,val_dir)
	for sid in val_ids:
		for song in song_id_dict[sid]:
			shutil.move(song,test_dir)


#create a csv file mapping song ids to songnames for every song in the database
#this will help evaluate the model

def map_id_to_song(spectrogram_dir,id_to_songname_dict):
	new_id_to_songname = {}
	for root,dirs,files in os.walk(spectrogram_dir):
		for filename in files:
			try:
				song_id = get_id_from_filename(filename)
				new_id_to_songname[song_id] = id_to_songname_dict[song_id]
			except KeyError:
				pass
	df = pd.DataFrame.from_dict(new_id_to_songname,orient='index')
	df.to_csv('Metadata\\database_id_to_songname.csv')

# Encoder object to help write dictionaries with numpy arrays to a file using the json library
class NumpyEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        return json.JSONEncoder.default(self, obj)



# Custom Data generator for loading images from disk while training
class DataGenerator(Sequence):
	def __init__(self,image_dir,labels_dict,output_dim,batch_size=32,dim=(256,256),n_channels=3,shuffle=True):
		self.dim = dim
		self.batch_size = batch_size
		self.labels = labels_dict
		for root,dirs,files in os.walk(image_dir):
			self.root = root
			self.image_ids = files
		self.n_channels = n_channels
		self.output_dim = output_dim
		self.shuffle = shuffle
		self.on_epoch_end()
	def __len__(self):
		return int(np.floor(len(self.image_ids)/self.batch_size))

	def __getitem__(self,index):
		indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]
		song_ids_temp = [self.image_ids[k] for k in indexes]
		X,y = self.__data_generation(song_ids_temp)
		return X,y
	def on_epoch_end(self):
		self.indexes = np.arange(len(self.image_ids))
		if self.shuffle == True:
			np.random.shuffle(self.indexes)
	def __data_generation(self,image_ids_temp):
		X = np.empty((self.batch_size,*self.dim,self.n_channels))
		y = np.empty((self.batch_size,self.output_dim),dtype='float64')

		for i,ID in enumerate(image_ids_temp):
			try:
				song_id = get_id_from_filename(ID)
				label = np.array(self.labels[song_id])
				image_path = os.path.join(self.root,ID)
				image = cv2.imread(image_path)
				image=cv2.resize(image,self.dim)
				image=img_to_array(image)
				image /= 255.0 #normalize pixel values
				means = image.mean(axis=(0,1), dtype='float64')
				image -= means
				X[i,] = image
				y[i,] = label
			except Exception as e:
				print('could not get {} , {}'.format(ID,e))
				pass

		return X,y

# Class defining the neural network along with a few functions for training and evaluation
class LFNet:
	def __init__(self,width,height,depth,output_dim,num_factors=100,load_checkpoint=False,load_json_model=False,**kwargs):
		self.width = width
		self.height = height
		self.depth = depth
		self.output_dim=output_dim
		self.num_factors=num_factors
		if load_checkpoint == True:
			self.model = load_model("Models\\network_model_checkpoint.hdf5")
			print('Loaded checkpoint from disk')
		if load_json_model == True:
			json_file = open(kwargs['model_json'], 'r')
			loaded_model_json = json_file.read()
			json_file.close()
			self.model = loaded_model = model_from_json(loaded_model_json)
			# load weights into new model
			self.model.load_weights(kwargs["model_path"])
			print("Loaded model from disk")


		else:
			self.model = self.build(self.width,self.height,self.depth)
			print('Building Model....')
		
	def build(self,width, height, depth):
		model = Sequential()
		input_shape = (height,width,depth)
		if K.image_data_format() == "channels_first":
			input_shape = (depth,height,width)
		model.add(Conv2D(16, (3,3),padding="same",input_shape=input_shape))
		model.add(Activation("relu"))
		model.add(MaxPooling2D(pool_size=(2,2),strides=(4,4)))
		model.add(Dropout(0.5))
		print('Built 1st Convolutional Layer With Dropout')

		model.add(Conv2D(32, (3,3),padding="same"))
		model.add(Activation("relu"))
		model.add(MaxPooling2D(pool_size=(2,2),strides=(4,4)))
		model.add(Dropout(0.5))
		print('Built 2nd Convolutional Layer with Dropout')

		model.add(Conv2D(64,(3,3),padding="same"))
		model.add(Activation("relu"))
		model.add(MaxPooling2D(pool_size=(2,2),strides=(4,4)))
		model.add(Dropout(0.5))
		print('Built 3d Convolutional Layer with Dropout')


		model.add(Flatten())
		model.add(Dense(self.num_factors,activation='relu'))
		model.add(Dropout(0.2))
		model.add(Dense(self.output_dim,activation='sigmoid'))
		print('Built fully connected layer with Dropout')
		print(model.summary())

		return model

	def train(self,training_generator,validation_generator,num_epochs,extend=False,**kwargs):
		opt = optimizers.Adam(lr=1e-4) 
		self.model.compile(loss="binary_crossentropy", optimizer=opt) 

		checkpoint = ModelCheckpoint("Models\\network_model_checkpoint.hdf5", monitor='loss', verbose=1,save_best_only=True, mode='auto', period=1)

		print("Training the model yo...")
		history = self.model.fit_generator(generator=training_generator,validation_data=validation_generator,epochs=num_epochs,callbacks=[checkpoint])
		model_json = self.model.to_json()
		with open('model.json','w') as json_file:
			json_file.write(model_json)
		self.model.save_weights('model.h5')
		print('saved model to disk')
		# save to json:  
		hist_df = pd.DataFrame(history.history) 
		hist_json_file = 'History\\history.json' 
		with open(hist_json_file, mode='w') as f:
			hist_df.to_json(f)
		# or save to csv: 
		hist_csv_file = 'History\\history.csv'
		with open(hist_csv_file, mode='w') as f:
			hist_df.to_csv(f)

	#create a text file mapping song and user ids to predicted latent factors
	def create_vector_encodings(self,image_dirs):
		song_id_to_prediction = {}
		get_song_embeddings = Model(inputs=self.model.input,outputs=self.model.get_layer(index=13).output) #Object which samples the output of the  13th hidden layer (latent factors) of the neural network
		user_embeddings = self.model.get_layer(index=15).get_weights() #Get weights of the 13th layer (each weight vector in this layer is assumed to be the user latent factors)
		print(user_embeddings[0].shape)
		user_id_to_prediction = get_labels_dictionary(user_embeddings[0],user_id_dir,transpose = True, load_npz = False, num_items=self.output_dim)

		#predict vector encodings from spectrograms in the dataset using the trained network
		for image_dir in image_dirs:
			for root,dirs,files in os.walk(image_dir):
				for file in files:
					ID = get_id_from_filename(file)
					imagepath = os.path.join(root,file)
					image=cv2.imread(imagepath)
					image=cv2.resize(image,(self.width,self.height))
					image=img_to_array(image)
					image /= 255.0 #normalize pixel values
					means = image.mean(axis=(0,1), dtype='float64') 
					image -= means #cente
					layer_output = get_song_embeddings.predict(np.asarray([image]))
					if ID not in song_id_to_prediction.keys():
						song_id_to_prediction[ID] = layer_output[0]
					else:
						song_id_to_prediction[ID] +=layer_output[0]  #Final vector encoding for a song is the sum of the vector encodings for each of its spectrograms
	 
		with open('Metadata\\song_id_to_prediction.txt', 'w') as file:
			file.write(json.dumps(song_id_to_prediction,cls=NumpyEncoder))
		with open('Metadata\\user_id_to_prediction.txt', 'w') as file:
			file.write(json.dumps(user_id_to_prediction,cls=NumpyEncoder))
		print('Successfuly dumped predicted vector encodings to {} and {}'.format('song_id_to_prediction.txt','user_id_to_prediction.txt'))

	def evaluate_predictions(self,id_to_latent_factor_dict,userid_to_latent_factor_dict,spectrogram_dir,num_users,id_to_songname_dict): #evaluate latent factor predictions
		get_song_embeddings = Model(inputs=self.model.input,outputs=self.model.get_layer(index=13).output)
		with open('Metadata\\song_id_to_prediction.txt') as f:
			song_id_to_prediction = json.loads(f.read())
		with open('Metadata\\user_id_to_prediction.txt') as f:
			user_id_to_prediction = json.loads(f.read())
		song_ids,song_predictions = zip(*(song_id_to_prediction.items())) #get song vectors generated by the cnn and the corresponding song ids
		user_ids,user_predictions = zip(*(user_id_to_prediction.items())) #get user vectors generated by the cnn and the corresponding user ids
		print('Predictions for {} songs in database created.....'.format(len(song_ids)))
		print('Predictions for {} users in database created.....'.format(len(user_ids)))
		new_subset_songs = [] 
		accuracy = [] # list containing recommendation accuracy for each user
		mAP = [] # list for containing mAP for each user
		song_ids_actual = [] #list of songs
		song_latent_factors = []
	#get latent factors for every song in the dataset
		for song in song_ids:
			try:
				song_latent_factors.append(id_to_latent_factor_dict[song])
			except KeyError:
				pass
		#build vector space with predicted latent factors
		t_pred_space = AnnoyIndex(self.num_factors,'angular')
		for i in range(len(song_predictions)):
			t_pred_space.add_item(i,song_predictions[i]) 
		t_pred_space.build(10)

		#build vector space with actual latent factors
		t_latent_space = AnnoyIndex(self.num_factors,'angular')
		for i in range(len(song_latent_factors)):
			t_latent_space.add_item(i,song_latent_factors[i])
		t_latent_space.build(10)
		user_count = 0
		for i in range(len(user_ids)):
			closest_songs_predicted = []
			closest_songs_actual = []
			user_id = user_ids[i]
			user_count+=1

			closest_songs = t_pred_space.get_nns_by_vector(user_predictions[i],500,include_distances = False) #get 500 closest songs to each user vector
			for index in closest_songs:
				try:
					closest_songs_predicted.append(id_to_songname_dict[song_ids[index]])
				except KeyError:
					pass										 #get the songids of the closest songs to the given user vector
			print("Closest songs generated by our network for user number {} ({}) is:".format(user_count,user_id))
			print(closest_songs_predicted[0:50])
			print('\n============================================\n')
			closest_songs_latent_space = t_latent_space.get_nns_by_vector(userid_to_latent_factor_dict[user_id],500,include_distances=False)
			for index in closest_songs_latent_space:
				try:
					closest_songs_actual.append(id_to_songname_dict[song_ids[index]])
				except KeyError:
					pass				
			print("Closest songs generated by latent factors for user number {} is:".format(user_count))
			print(closest_songs_actual[0:50])
			print('\n')


			map_user = ml_metrics.mapk(closest_songs_actual,closest_songs_predicted,k=500)
			good_recom = set(closest_songs_actual) & set(closest_songs_predicted)
			good_recom_count = len(good_recom)
			accuracy_user = (good_recom_count/500)*100
			#print("The accuracy for this user is {} ".format(accuracy_user))
			print("The map for this user is {} ".format(map_user))
			print('\n')
			accuracy.append(accuracy_user)
			mAP.append(map_user)
		total_accuracy = sum(accuracy)/user_count
		total_map = sum(mAP)/user_count
		print('\n The mAP of the recommendations for {} users is {} '.format(user_count,total_map))
		print('The accuracy of the recommendations for {} users is {}%'.format(user_count,total_accuracy))
		return total_accuracy

	#find closest songs predicted by the cnn to a song in the msd dataset
	def find_closest_songs(self,song_id,id_songname_dict):
		layer_outputs = []
		get_song_embeddings = Model(inputs=self.model.input,outputs=self.model.get_layer(index=13).output)
		with open('Metadata\\song_id_to_prediction.txt') as f:
			song_id_to_prediction = json.loads(f.read())
			#print(song_id_to_prediction)
		song_ids,song_predictions = zip(*(song_id_to_prediction.items())) #prediction for the given song is the average of all spectrogram latent factors
		#song_predictions = np.array(song_predictions)

		t = AnnoyIndex(self.num_factors,'angular')
		for i in range(len(song_predictions)):
			t.add_item(i,song_predictions[i]) #assign each predicted latent factor and index
		t.build(10)
		closest_songs_indexes = t.get_nns_by_item(song_ids.index(song_id),10)
		print("The most similar songs to {} are:".format(id_songname_dict[song_id]))
		for index in closest_songs_indexes:
			try:
				print(id_songname_dict[song_ids[index]])
			except KeyError:
				pass

	#find the closest songs predicted by the CNN for a given spectrogram
	def find_closest_songs_by_spec(self,spectrogram_dir,id_songname_dict):
		get_song_embeddings = Model(inputs=self.model.input,outputs=self.model.get_layer(index=13).output)
		prediction_vectors = []
		for root,dirs,files in os.walk(spectrogram_dir):
			for file in files:
				songname= get_id_from_filename(file)
				imagepath = os.path.join(root,file)
				image=cv2.imread(imagepath)
				image=cv2.resize(image,(self.width,self.height))
				image=img_to_array(image)
				image /= 255.0 #normalize pixel values
				means = image.mean(axis=(0,1), dtype='float64') 
				image -= means #cente
				layer_output = get_song_embeddings.predict(np.asarray([image]))
				prediction_vectors.append(layer_output[0])
		final_prediction = sum(prediction_vectors)

		with open('Metadata\\song_id_to_prediction.txt') as f:
			song_id_to_prediction = json.loads(f.read())
			#print(song_id_to_prediction)
		song_ids,song_predictions = zip(*(song_id_to_prediction.items())) #prediction for the given song is the average of all spectrogram latent factors
		#song_predictions = np.array(song_predictions)

		t = AnnoyIndex(self.num_factors,'angular')
		for i in range(len(song_predictions)):
			t.add_item(i,song_predictions[i]) #assign each predicted latent factor and index
		t.build(10)
		closest_songs_indexes = t.get_nns_by_vector(final_prediction,10)
		print("The most similar songs to {} are:".format(songname))
		for index in closest_songs_indexes:
			try:
				print(id_songname_dict[song_ids[index]])
			except KeyError:
				pass

	#function to visualize intermediate activations in the CNN			
	def visualize_layer_outputs(self,layer_number,spectrogram_path):
		get_layer_activations = Model(inputs=self.model.input,outputs=self.model.get_layer(index=layer_number).output)
		for root,dirs,files in os.walk(spectrogram_path):
			for file in files:
				songname= get_id_from_filename(file)
				imagepath = os.path.join(root,file)
				image=cv2.imread(imagepath)
				image=cv2.resize(image,(self.width,self.height))
				image=img_to_array(image)
				image /= 255.0 #normalize pixel values
				means = image.mean(axis=(0,1), dtype='float64') 
				image -= means #cente
		layer_activations = get_layer_activations.predict(np.asarray([image]))
		print(layer_activations[0].shape)
		plt.matshow(layer_activations[0][0], cmap='viridis')	
		plt.show()		





	
if __name__=='__main__':

	parser = argparse.ArgumentParser(description = 'Script for generating music recommendations using a CNN...')
	parser.add_argument('--train_network',default='False',help='Use to retrain CNN on custom dataset, specify training dataset path using --train_path')
	parser.add_argument('--split_data',nargs=2,type = int, help='Specify percentage of test and validation samples')
	parser.add_argument('--dataset_path',default=spectrogram_dir,help='Specify dataset path')
	parser.add_argument('--train_path',default=training_dir,help='Specify training dataset path')
	parser.add_argument('--val_path',default=validation_dir,help='Specify validation dataset path')
	parser.add_argument('--test_path',default=test_dir,help='Specify test dataset path')
	parser.add_argument('--num_epochs',type = int, default=10,help = 'Specify number of training epochs')
	parser.add_argument('--load_checkpoint',default='False',help = 'Use if training was abruptly stopped')
	parser.add_argument('--train_newmodel',default='False',help = 'Use if youd like to train a new network')
	parser.add_argument('--new_idfile',default = 'False', help = 'Generate new csv mapping song id to songname (use when updating dataset)')
	parser.add_argument('--find_closest_songs',default = None,help = 'Specify whether predictions are to made from spectrograms or using msd id')
	parser.add_argument('--msd_id',help='Specify msd to find closest songs for')
	parser.add_argument('--spec_path',default = None, help='Specify spectrgram path for which predictions are to be made')
	parser.add_argument('--evaluate_predictions',default= None, help='Use to evaluate predictions')
	parser.add_argument('--load_model_json',nargs=2,help='Specify path to model saved in json format')
	parser.add_argument('--disp_layer',type = int, help='Use to visualize intermediate layer activations')
	arguments = parser.parse_args()

	id_to_vec = get_labels_dictionary(song_latent_factors_dir,song_msd_id_dir) # get dictionary mapping song_ids to song latent factors
	userid_to_vec = get_labels_dictionary(user_latent_factors_dir,user_id_dir) # get dictionary mapping user_ids to user latent factors

	if(arguments.split_data is not None):
		if(arguments.train_path is None):
			print('Specify training directory using --train_path')
		if(arguments.val_path is None):
			print('Specify validation directory using --val_path')
		if(arguments.test_path is None):
			print('Specify test directory using --test_path')
		if(arguments.split_data is None):
			print('Specify percentage of test and validation samples using --split_data')
		else:
			map_id_to_song(arguments.dataset_path,id_to_songname_dict)
			split_data(arguments.dataset_path,arguments.train_path,arguments.val_path,arguments.test_path,id_to_vec,arguments.split_data[0],arguments.split_data[1])
	if(arguments.new_idfile == True):
		if(arguments.dataset_path is None):
			print('Specify dataset path using --dataset_path')
		else:
			map_id_to_song(arguments.dataset_path,id_to_songname_dict)

	if(arguments.train_network == 'True'):
		if(arguments.train_path is None):
			print('Specify training directory using --train_path')
		if(arguments.val_path is None):
			print('Specify validation directory using --val_path')
		if(arguments.test_path is None):
			print('Specify test directory using --test_path')
		else:
			num_songs,subset_songs = get_msd_ids_from_dataset(arguments.dataset_path,song_msd_id_dir,id_to_vec)
	#create user based encoding
			print('Creating Output labels for the dataset\n')
			print('This may take a few minutes....\n')
			num_users,subset_users = get_user_ids_list(user_id_dir,20000,userid_to_vec)
			create_output_labels(subset_songs,subset_users,userid_to_vec,id_to_vec)
			with open('Metadata\\user_based_labels.json') as f:
				labels_dict = json.loads(f.read())
			print('Successfuly created output labels :) ... ')
			training_generator = DataGenerator(arguments.train_path,labels_dict,20000)
			validation_generator = DataGenerator(arguments.val_path,labels_dict,20000)

			if(arguments.train_newmodel == 'True'):
				Network = LFNet(256,256,3,20000)
			if(arguments.load_checkpoint == 'True'):
				Network = LFNet(256,256,3,20000,load_checkpoint=True)
			if(arguments.load_model_json is not None):
				Network = LFNet(256,256,3,20000,load_model_json=True,model_json = arguments.load_model_json[0],model_path=arguments.load_model_json[1])
			else:
				Network = LFNet(256,256,3,20000,load_json_model=True,model_json='Models\\model 4.7.json',model_path='Models\\model 4.7.h5')
			Network.train(training_generator,validation_generator,arguments.num_epochs)
			print('Training Completed.....\n')	
			print('Creating Vector encoding from trained network for users and songs.....')
			print('This may take a few minutes......\n')
			Network.create_vector_encodings([arguments.train_path,arguments.val_path,arguments.test_path])

	#evaluate model recommendations
	if(arguments.train_network == 'False'):
		Network = LFNet(256,256,3,20000,load_json_model=True,model_json='Models\\model 4.7.json',model_path='Models\\model 4.7.h5')	

	song_df = pd.read_csv(id_to_songname_dir,sep='=',usecols= ['artist_name','song_name','msd_id'],encoding = "ISO-8859-1")
	song_df['artist_song_name'] = song_df['artist_name'].str.cat(song_df['song_name'],sep=' ')
	id_to_songname_dict = dict(zip(song_df.msd_id,song_df.artist_song_name))
	user_latent_factors = np.load(user_latent_factors_dir)['arr_0']
	subset_songs = np.load(song_msd_id_dir)
	if(arguments.evaluate_predictions == 'True'):
		Network.evaluate_predictions(id_to_vec,userid_to_vec,arguments.dataset_path,20000,id_to_songname_dict)
	if(arguments.disp_layer is not None):
		if(arguments.spec_path is None):
			print('Enter the path to a spectrogram to input to the network using --spec_path')
			Network.visualize_layer_outputs(arguments.disp_layer,arguments.spec_path)
	if(arguments.find_closest_songs == 'msd'):
		if(arguments.msd_id is None):
			print('Specify msd id of song to predict using --msd_id')
		else:
			Network.find_closest_songs(arguments.msd_id,id_to_songname_dict)
	if(arguments.find_closest_songs == 'spec'):
		if(arguments.spec_path is None):
			print('Specify path of spectrogram to predict using --spec_path')
		else:
			Network.find_closest_songs_by_spec(arguments.spec_path,id_to_songname_dict)

